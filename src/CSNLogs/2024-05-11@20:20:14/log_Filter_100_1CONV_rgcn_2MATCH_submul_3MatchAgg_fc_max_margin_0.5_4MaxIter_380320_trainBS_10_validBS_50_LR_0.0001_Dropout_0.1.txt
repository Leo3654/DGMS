    Parameter               Value        
=========================================
conv                rgcn                 
data_dir            ../../../cosqa/csnPro
dropout             0.1                  
filters             100                  
gpu_index           3                    
log_dir             ../CSNLogs/          
lr                  0.0001               
margin              0.5                  
match               submul               
match_agg           fc_max               
max_iter            380320               
model_path          .                    
only_test           False                
print_interval      2000                 
random_split        True                 
skip_file_check     False                
test_chunk_size     100                  
train_batch_size    10                   
train_sample_size   380320               
val_start           190000               
valid_batch_size    50                   
valid_interval      19000                

****CPU or GPU: cuda
GraphMatchNetwork(
  (GraphEncoder_1): RGCNConv(300, 100, num_relations=3)
  (fc_match): Linear(in_features=200, out_features=100, bias=True)
  (fc_agg): Linear(in_features=100, out_features=100, bias=True)
)
Init Reading Code Graphs ... 
Train=380320
Valid=20000
Test=1000
Init Reading Text Graphs ... 
Train=380320
Valid=20000
Test=1000
#Valid Iter 0: loss = #0.4989757537841797# (Decrease) < Best loss = 0.4989757537841797. Save to best model..., time elapsed = 0:00:28.902149.
Start to testing ...

&Testing Iteration 0: for 1000 queries finished. Time elapsed = 0:01:28.143743.
&Testing Iteration 0: MRR = &0.055894929853304416&
&Testing Iteration 0: S@1@ = &0.012&
&Testing Iteration 0: S@5@ = &0.061&
&Testing Iteration 0: S@10@ = &0.103&
S@1, S@5, S@10
0.012, 0.061, 0.103
@Train Iter 2000: mean smooth loss = @0.4284152388572693@, time = 0:03:12.209699.
@Train Iter 4000: mean smooth loss = @0.3236139416694641@, time = 0:01:08.523668.
@Train Iter 6000: mean smooth loss = @0.28528857231140137@, time = 0:01:22.029402.
@Train Iter 8000: mean smooth loss = @0.25974100828170776@, time = 0:01:40.422323.
@Train Iter 10000: mean smooth loss = @0.24343043565750122@, time = 0:01:12.078190.
@Train Iter 12000: mean smooth loss = @0.23239751160144806@, time = 0:01:09.256903.
@Train Iter 14000: mean smooth loss = @0.21866820752620697@, time = 0:01:17.966879.
@Train Iter 16000: mean smooth loss = @0.2085878700017929@, time = 0:01:18.822560.
@Train Iter 18000: mean smooth loss = @0.1956981122493744@, time = 0:01:17.184486.
@Train Iter 20000: mean smooth loss = @0.17865903675556183@, time = 0:01:09.254257.
@Train Iter 22000: mean smooth loss = @0.17047420144081116@, time = 0:01:21.310664.
@Train Iter 24000: mean smooth loss = @0.16457156836986542@, time = 0:01:35.351963.
@Train Iter 26000: mean smooth loss = @0.15651150047779083@, time = 0:01:14.390074.
@Train Iter 28000: mean smooth loss = @0.15172141790390015@, time = 0:01:14.814966.
@Train Iter 30000: mean smooth loss = @0.14722490310668945@, time = 0:01:23.784701.
@Train Iter 32000: mean smooth loss = @0.14429481327533722@, time = 0:01:39.392610.
@Train Iter 34000: mean smooth loss = @0.14205490052700043@, time = 0:01:33.219805.
@Train Iter 36000: mean smooth loss = @0.13861620426177979@, time = 0:01:32.319306.
@Train Iter 38000: mean smooth loss = @0.13530413806438446@, time = 0:01:15.668695.
@Train Iter 40000: mean smooth loss = @0.1320871114730835@, time = 0:01:07.582505.
@Train Iter 42000: mean smooth loss = @0.13061563670635223@, time = 0:01:26.797931.
@Train Iter 44000: mean smooth loss = @0.12878723442554474@, time = 0:01:17.704441.
@Train Iter 46000: mean smooth loss = @0.12789520621299744@, time = 0:01:17.746385.
@Train Iter 48000: mean smooth loss = @0.1272188127040863@, time = 0:01:22.609681.
@Train Iter 50000: mean smooth loss = @0.12266787141561508@, time = 0:01:16.199965.
@Train Iter 52000: mean smooth loss = @0.1214851438999176@, time = 0:01:17.768138.
@Train Iter 54000: mean smooth loss = @0.12203089892864227@, time = 0:01:07.941195.
@Train Iter 56000: mean smooth loss = @0.11797020584344864@, time = 0:01:07.402832.
@Train Iter 58000: mean smooth loss = @0.1164688691496849@, time = 0:01:09.859531.
@Train Iter 60000: mean smooth loss = @0.11608592420816422@, time = 0:01:22.720531.
@Train Iter 62000: mean smooth loss = @0.118243008852005@, time = 0:01:11.097453.
@Train Iter 64000: mean smooth loss = @0.11216917634010315@, time = 0:01:08.541741.
@Train Iter 66000: mean smooth loss = @0.11647340655326843@, time = 0:01:10.668382.
@Train Iter 68000: mean smooth loss = @0.11305076628923416@, time = 0:01:14.328387.
@Train Iter 70000: mean smooth loss = @0.11379921436309814@, time = 0:01:14.310089.
@Train Iter 72000: mean smooth loss = @0.11273010820150375@, time = 0:01:10.514246.
@Train Iter 74000: mean smooth loss = @0.110820472240448@, time = 0:01:10.003276.
@Train Iter 76000: mean smooth loss = @0.1129576787352562@, time = 0:01:09.121196.
@Train Iter 78000: mean smooth loss = @0.10519164055585861@, time = 0:01:24.114487.
@Train Iter 80000: mean smooth loss = @0.10797403752803802@, time = 0:01:35.451688.
@Train Iter 82000: mean smooth loss = @0.10424931347370148@, time = 0:01:29.321123.
@Train Iter 84000: mean smooth loss = @0.10573224723339081@, time = 0:01:28.119928.
@Train Iter 86000: mean smooth loss = @0.10203415155410767@, time = 0:01:22.717610.
@Train Iter 88000: mean smooth loss = @0.10727740079164505@, time = 0:01:42.072874.
@Train Iter 90000: mean smooth loss = @0.10276946425437927@, time = 0:01:27.174193.
@Train Iter 92000: mean smooth loss = @0.10459984093904495@, time = 0:01:22.435432.
@Train Iter 94000: mean smooth loss = @0.10531637817621231@, time = 0:01:18.481700.
@Train Iter 96000: mean smooth loss = @0.10569638758897781@, time = 0:01:18.997918.
@Train Iter 98000: mean smooth loss = @0.10507676750421524@, time = 0:01:18.319527.
@Train Iter 100000: mean smooth loss = @0.10180974006652832@, time = 0:01:19.320260.
@Train Iter 102000: mean smooth loss = @0.10092946141958237@, time = 0:01:20.840815.
@Train Iter 104000: mean smooth loss = @0.10324778407812119@, time = 0:01:20.758042.
@Train Iter 106000: mean smooth loss = @0.10031203180551529@, time = 0:01:20.901799.
@Train Iter 108000: mean smooth loss = @0.10431195050477982@, time = 0:01:33.750735.
@Train Iter 110000: mean smooth loss = @0.09898039698600769@, time = 0:01:35.838166.
@Train Iter 112000: mean smooth loss = @0.09874989092350006@, time = 0:01:29.144832.
@Train Iter 114000: mean smooth loss = @0.10257045179605484@, time = 0:01:08.252734.
@Train Iter 116000: mean smooth loss = @0.09673891216516495@, time = 0:01:08.617489.
@Train Iter 118000: mean smooth loss = @0.09380339086055756@, time = 0:01:08.111363.
@Train Iter 120000: mean smooth loss = @0.09713522344827652@, time = 0:01:21.151140.
@Train Iter 122000: mean smooth loss = @0.09657414257526398@, time = 0:01:30.717712.
@Train Iter 124000: mean smooth loss = @0.09732679277658463@, time = 0:01:42.204084.
@Train Iter 126000: mean smooth loss = @0.09633331745862961@, time = 0:01:43.192417.
@Train Iter 128000: mean smooth loss = @0.09810630977153778@, time = 0:01:26.627888.
@Train Iter 130000: mean smooth loss = @0.09800384938716888@, time = 0:01:27.566880.
@Train Iter 132000: mean smooth loss = @0.09762264788150787@, time = 0:01:08.468813.
@Train Iter 134000: mean smooth loss = @0.09609261155128479@, time = 0:01:18.641025.
@Train Iter 136000: mean smooth loss = @0.09324397891759872@, time = 0:01:18.810955.
@Train Iter 138000: mean smooth loss = @0.09582795202732086@, time = 0:01:20.150645.
@Train Iter 140000: mean smooth loss = @0.0919184535741806@, time = 0:01:07.570239.
@Train Iter 142000: mean smooth loss = @0.09536022692918777@, time = 0:01:07.581715.
@Train Iter 144000: mean smooth loss = @0.09404987096786499@, time = 0:01:13.922577.
@Train Iter 146000: mean smooth loss = @0.09544079005718231@, time = 0:01:09.367993.
@Train Iter 148000: mean smooth loss = @0.09091252088546753@, time = 0:01:08.956178.
@Train Iter 150000: mean smooth loss = @0.09148842096328735@, time = 0:01:18.825082.
@Train Iter 152000: mean smooth loss = @0.09484642744064331@, time = 0:01:19.550481.
@Train Iter 154000: mean smooth loss = @0.0889122411608696@, time = 0:01:24.387259.
@Train Iter 156000: mean smooth loss = @0.09234011918306351@, time = 0:01:42.687788.
@Train Iter 158000: mean smooth loss = @0.08885349333286285@, time = 0:01:42.107055.
@Train Iter 160000: mean smooth loss = @0.08825520426034927@, time = 0:01:18.861257.
@Train Iter 162000: mean smooth loss = @0.0923415869474411@, time = 0:01:21.427371.
@Train Iter 164000: mean smooth loss = @0.0932554379105568@, time = 0:01:29.646026.
@Train Iter 166000: mean smooth loss = @0.08915847539901733@, time = 0:01:35.793626.
@Train Iter 168000: mean smooth loss = @0.08928031474351883@, time = 0:01:20.964391.
@Train Iter 170000: mean smooth loss = @0.0877286046743393@, time = 0:01:20.665966.
@Train Iter 172000: mean smooth loss = @0.08887345343828201@, time = 0:01:19.098530.
@Train Iter 174000: mean smooth loss = @0.09049330651760101@, time = 0:01:22.471724.
@Train Iter 176000: mean smooth loss = @0.09075967222452164@, time = 0:01:17.022579.
@Train Iter 178000: mean smooth loss = @0.08774406462907791@, time = 0:01:24.849714.
@Train Iter 180000: mean smooth loss = @0.08735593408346176@, time = 0:01:16.031956.
@Train Iter 182000: mean smooth loss = @0.08884266763925552@, time = 0:01:24.948930.
@Train Iter 184000: mean smooth loss = @0.08656933903694153@, time = 0:01:07.841264.
@Train Iter 186000: mean smooth loss = @0.08745630085468292@, time = 0:01:06.626786.
@Train Iter 188000: mean smooth loss = @0.08980368077754974@, time = 0:01:07.444293.
@Train Iter 190000: mean smooth loss = @0.08837458491325378@, time = 0:01:07.507840.
#Valid Iter 190000: loss = #0.0892883762717247# (Decrease) < Best loss = 0.0892883762717247. Save to best model..., time elapsed = 0:00:28.232278.
@Train Iter 192000: mean smooth loss = @0.08484338223934174@, time = 0:01:48.136674.
@Train Iter 194000: mean smooth loss = @0.08527366071939468@, time = 0:01:06.367946.
@Train Iter 196000: mean smooth loss = @0.08538894355297089@, time = 0:01:24.703564.
@Train Iter 198000: mean smooth loss = @0.08483687788248062@, time = 0:01:42.535364.
@Train Iter 200000: mean smooth loss = @0.0838068425655365@, time = 0:01:35.540602.
@Train Iter 202000: mean smooth loss = @0.08446341753005981@, time = 0:01:15.380849.
@Train Iter 204000: mean smooth loss = @0.08272594958543777@, time = 0:01:12.410747.
@Train Iter 206000: mean smooth loss = @0.08487091213464737@, time = 0:01:07.913579.
@Train Iter 208000: mean smooth loss = @0.0806749239563942@, time = 0:01:08.703958.
#Valid Iter 209000: loss = #0.08692479878664017# (Decrease) < Best loss = 0.08692479878664017. Save to best model..., time elapsed = 0:00:27.700905.
@Train Iter 210000: mean smooth loss = @0.08205581456422806@, time = 0:01:36.850986.
@Train Iter 212000: mean smooth loss = @0.0859680250287056@, time = 0:01:10.225562.
@Train Iter 214000: mean smooth loss = @0.08533060550689697@, time = 0:01:10.107795.
@Train Iter 216000: mean smooth loss = @0.08508944511413574@, time = 0:01:08.625351.
@Train Iter 218000: mean smooth loss = @0.08608556538820267@, time = 0:01:29.396102.
@Train Iter 220000: mean smooth loss = @0.08658751100301743@, time = 0:01:19.406152.
@Train Iter 222000: mean smooth loss = @0.08607558161020279@, time = 0:01:10.875219.
@Train Iter 224000: mean smooth loss = @0.08636423945426941@, time = 0:01:08.390937.
@Train Iter 226000: mean smooth loss = @0.08541920781135559@, time = 0:01:23.073300.
@Train Iter 228000: mean smooth loss = @0.08462902903556824@, time = 0:01:12.830903.
#Valid Iter 228000: loss = #0.08860514312982559# (Increase). Best val loss = 0.08692479878664017, time elapsed = 0:00:28.732976.
@Train Iter 230000: mean smooth loss = @0.08201432228088379@, time = 0:02:09.802373.
@Train Iter 232000: mean smooth loss = @0.08083154261112213@, time = 0:01:37.077249.
@Train Iter 234000: mean smooth loss = @0.08123023808002472@, time = 0:01:26.164003.
@Train Iter 236000: mean smooth loss = @0.08129866421222687@, time = 0:01:24.153051.
@Train Iter 238000: mean smooth loss = @0.08118755370378494@, time = 0:01:30.968786.
@Train Iter 240000: mean smooth loss = @0.08184325695037842@, time = 0:01:17.352703.
@Train Iter 242000: mean smooth loss = @0.08149506896734238@, time = 0:01:16.363719.
@Train Iter 244000: mean smooth loss = @0.08362934738397598@, time = 0:01:28.006522.
@Train Iter 246000: mean smooth loss = @0.08082404732704163@, time = 0:01:16.612539.
#Valid Iter 247000: loss = #0.08499369770288467# (Decrease) < Best loss = 0.08499369770288467. Save to best model..., time elapsed = 0:00:31.219052.
@Train Iter 248000: mean smooth loss = @0.08310160785913467@, time = 0:01:49.969795.
@Train Iter 250000: mean smooth loss = @0.08327437937259674@, time = 0:01:44.590229.
@Train Iter 252000: mean smooth loss = @0.08206246793270111@, time = 0:01:35.212944.
@Train Iter 254000: mean smooth loss = @0.08384017646312714@, time = 0:01:20.743370.
@Train Iter 256000: mean smooth loss = @0.08056594431400299@, time = 0:01:20.504912.
@Train Iter 258000: mean smooth loss = @0.08364397287368774@, time = 0:01:19.548756.
@Train Iter 260000: mean smooth loss = @0.08137676864862442@, time = 0:01:12.600561.
@Train Iter 262000: mean smooth loss = @0.08095838874578476@, time = 0:01:07.299728.
@Train Iter 264000: mean smooth loss = @0.08302287012338638@, time = 0:01:14.311996.
@Train Iter 266000: mean smooth loss = @0.08281796425580978@, time = 0:01:29.068887.
#Valid Iter 266000: loss = #0.08694124221801758# (Increase). Best val loss = 0.08499369770288467, time elapsed = 0:00:28.696827.
@Train Iter 268000: mean smooth loss = @0.07941915839910507@, time = 0:01:36.080793.
@Train Iter 270000: mean smooth loss = @0.07857964187860489@, time = 0:01:07.647540.
@Train Iter 272000: mean smooth loss = @0.07675515115261078@, time = 0:01:16.584701.
@Train Iter 274000: mean smooth loss = @0.07921119779348373@, time = 0:01:19.597174.
@Train Iter 276000: mean smooth loss = @0.0799381360411644@, time = 0:01:12.719125.
@Train Iter 278000: mean smooth loss = @0.07785382866859436@, time = 0:01:09.033342.
@Train Iter 280000: mean smooth loss = @0.08035410195589066@, time = 0:01:06.258233.
@Train Iter 282000: mean smooth loss = @0.07643957436084747@, time = 0:01:07.654904.
@Train Iter 284000: mean smooth loss = @0.07849396020174026@, time = 0:01:08.770256.
#Valid Iter 285000: loss = #0.08618859201669693# (Increase). Best val loss = 0.08499369770288467, time elapsed = 0:00:27.687998.
@Train Iter 286000: mean smooth loss = @0.08142514526844025@, time = 0:01:36.807251.
@Train Iter 288000: mean smooth loss = @0.07755503058433533@, time = 0:01:29.245500.
@Train Iter 290000: mean smooth loss = @0.08119213581085205@, time = 0:01:08.739100.
@Train Iter 292000: mean smooth loss = @0.07944873720407486@, time = 0:01:28.056858.
@Train Iter 294000: mean smooth loss = @0.07870080322027206@, time = 0:01:26.618453.
@Train Iter 296000: mean smooth loss = @0.07758530974388123@, time = 0:01:36.565724.
@Train Iter 298000: mean smooth loss = @0.0789961889386177@, time = 0:01:19.714208.
@Train Iter 300000: mean smooth loss = @0.0802064836025238@, time = 0:01:18.089649.
@Train Iter 302000: mean smooth loss = @0.08005477488040924@, time = 0:01:19.649549.
@Train Iter 304000: mean smooth loss = @0.07854997366666794@, time = 0:01:19.734515.
#Valid Iter 304000: loss = #0.08487196266651154# (Decrease) < Best loss = 0.08487196266651154. Save to best model..., time elapsed = 0:00:31.210269.
@Train Iter 306000: mean smooth loss = @0.07482537627220154@, time = 0:01:51.171001.
@Train Iter 308000: mean smooth loss = @0.07566823065280914@, time = 0:01:17.522402.
@Train Iter 310000: mean smooth loss = @0.0778219923377037@, time = 0:01:13.180013.
@Train Iter 312000: mean smooth loss = @0.07764355838298798@, time = 0:01:10.283537.
@Train Iter 314000: mean smooth loss = @0.07832449674606323@, time = 0:01:20.715809.
@Train Iter 316000: mean smooth loss = @0.07534505426883698@, time = 0:01:38.422379.
@Train Iter 318000: mean smooth loss = @0.07641952484846115@, time = 0:01:23.392402.
@Train Iter 320000: mean smooth loss = @0.07798027247190475@, time = 0:01:23.970116.
@Train Iter 322000: mean smooth loss = @0.07701906561851501@, time = 0:01:18.619594.
#Valid Iter 323000: loss = #0.08377993851900101# (Decrease) < Best loss = 0.08377993851900101. Save to best model..., time elapsed = 0:00:28.544281.
@Train Iter 324000: mean smooth loss = @0.07401612401008606@, time = 0:01:52.224766.
@Train Iter 326000: mean smooth loss = @0.07856721431016922@, time = 0:01:18.537842.
@Train Iter 328000: mean smooth loss = @0.07786183059215546@, time = 0:01:16.222980.
@Train Iter 330000: mean smooth loss = @0.07781990617513657@, time = 0:01:08.840993.
@Train Iter 332000: mean smooth loss = @0.07774458080530167@, time = 0:01:22.637272.
@Train Iter 334000: mean smooth loss = @0.07660239934921265@, time = 0:01:13.148545.
@Train Iter 336000: mean smooth loss = @0.07481207698583603@, time = 0:01:25.142775.
@Train Iter 338000: mean smooth loss = @0.07585637271404266@, time = 0:01:12.336807.
@Train Iter 340000: mean smooth loss = @0.07617246359586716@, time = 0:01:32.248376.
@Train Iter 342000: mean smooth loss = @0.0758037194609642@, time = 0:01:09.776534.
#Valid Iter 342000: loss = #0.08175008744001389# (Decrease) < Best loss = 0.08175008744001389. Save to best model..., time elapsed = 0:00:27.771695.
@Train Iter 344000: mean smooth loss = @0.07228563725948334@, time = 0:01:36.701023.
@Train Iter 346000: mean smooth loss = @0.07504476606845856@, time = 0:01:22.084736.
@Train Iter 348000: mean smooth loss = @0.07298783957958221@, time = 0:01:10.398879.
@Train Iter 350000: mean smooth loss = @0.07503041625022888@, time = 0:01:22.742945.
@Train Iter 352000: mean smooth loss = @0.07414162158966064@, time = 0:01:14.870887.
@Train Iter 354000: mean smooth loss = @0.07622472196817398@, time = 0:01:08.846139.
@Train Iter 356000: mean smooth loss = @0.074747234582901@, time = 0:01:09.948712.
@Train Iter 358000: mean smooth loss = @0.0745217427611351@, time = 0:01:31.745059.
@Train Iter 360000: mean smooth loss = @0.07639133185148239@, time = 0:01:30.730404.
#Valid Iter 361000: loss = #0.08312126249074936# (Increase). Best val loss = 0.08175008744001389, time elapsed = 0:00:28.261942.
@Train Iter 362000: mean smooth loss = @0.07531112432479858@, time = 0:01:36.241866.
@Train Iter 364000: mean smooth loss = @0.0770648866891861@, time = 0:01:16.655239.
@Train Iter 366000: mean smooth loss = @0.07375356554985046@, time = 0:01:27.713623.
@Train Iter 368000: mean smooth loss = @0.0768963098526001@, time = 0:01:34.222106.
@Train Iter 370000: mean smooth loss = @0.07877469062805176@, time = 0:01:10.640640.
@Train Iter 372000: mean smooth loss = @0.07786163687705994@, time = 0:01:10.685199.
@Train Iter 374000: mean smooth loss = @0.07585644721984863@, time = 0:01:23.416473.
@Train Iter 376000: mean smooth loss = @0.07712496072053909@, time = 0:01:15.590233.
@Train Iter 378000: mean smooth loss = @0.07632072269916534@, time = 0:01:15.895577.
@Train Iter 380000: mean smooth loss = @0.07452166080474854@, time = 0:01:13.011869.
#Valid Iter 380000: loss = #0.08236224204301834# (Increase). Best val loss = 0.08175008744001389, time elapsed = 0:00:29.826146.
finished to load the model, next to start to test and time is = 2024-05-12 00:44:46.588355
Start to testing ...

&Testing Iteration 380321: for 1000 queries finished. Time elapsed = 0:01:42.806631.
&Testing Iteration 380321: MRR = &0.579879512111602&
&Testing Iteration 380321: S@1@ = &0.438&
&Testing Iteration 380321: S@5@ = &0.75&
&Testing Iteration 380321: S@10@ = &0.849&
S@1, S@5, S@10
0.438, 0.75, 0.849

All Finished using (0:01:42.809344)

